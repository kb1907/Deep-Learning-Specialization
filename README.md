# Deep Learning Specialization
Deep Learning Specialization - Projects- Notes

----------------------------------------

<img src="https://aikademi.com/wp-content/uploads/2018/01/deeplearning.png" width="550" height="450">

### WHAT  I LEARN

- Build and train deep neural networks, identify key architecture parameters, implement vectorized neural networks and deep learning to applications

- Train test sets, analyze variance for DL applications, use standard techniques and optimization algorithms, and build neural networks in TensorFlow

- Build a CNN and apply it to detection and recognition tasks, use neural style transfer to generate art, and apply algorithms to image and video data

- Build and train RNNs, work with NLP and Word Embeddings, and use HuggingFace tokenizers and transformer models to perform NER and Question Answering


#### Reference
- In this folder, [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) projects and notes can be found.

- **DeepLearning.AI** makes these slides available for educational purposes. 

- All the best ðŸ¤˜


### There are 5 Courses in this Specialization
--------------------------------------------------

## Course 1 Neural Networks and Deep Learning

- [In the first course of the Deep Learning Specialization](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning), I study the foundational concept of neural networks and deep learning. 

- By the end,  I am familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural networkâ€™s architecture; and apply deep learning to my own applications.


## Course 2 Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

- In the second course of the Deep Learning Specialization, course open the deep learning black box to understand the processes that drive performance and generate good results systematically. 

- By the end, I learn the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence; and implement a neural network in TensorFlow.

## Course 3 Structuring Machine Learning Projects

- In the third course of the Deep Learning Specialization, I learn how to build a successful machine learning project and get to practice decision-making as a machine learning project leader. 

- By the end, I am able to diagnose errors in a machine learning system; prioritize strategies for reducing errors; understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance; and apply end-to-end learning, transfer learning, and multi-task learning.


## Course 4 Convolutional Neural Networks

- In the fourth course of the Deep Learning Specialization, I understand how computer vision has evolved and become familiar with its exciting applications such as autonomous driving, face recognition, reading radiology images, and more.

- By the end, I am able to build a convolutional neural network, including recent variations such as residual networks; apply convolutional networks to visual detection and recognition tasks; and use neural style transfer to generate art and apply these algorithms to a variety of image, video, and other 2D or 3D data. 

## Course 5 Sequence Models

- In the fifth course of the Deep Learning Specialization, I become familiar with sequence models and their exciting applications such as speech recognition, music synthesis, chatbots, machine translation, natural language processing (NLP), and more. 

- By the end, I am able to build and train Recurrent Neural Networks (RNNs) and commonly-used variants such as GRUs and LSTMs; apply RNNs to Character-level Language Modeling; gain experience with natural language processing and Word Embeddings; and use HuggingFace tokenizers and transformer models to solve different NLP tasks such as NER and Question Answering.



